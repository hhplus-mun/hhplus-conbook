## 데이터 접근 성능 개선을 위한 캐싱 설계 보고서

### 서론
캐싱은 데이터를 임시로 저장해두는 저장소 계층으로, API 응답을 빠르게 처리하고 시스템 부하를 <br>
줄이기 위해 사용된다. 간단히 말해 캐싱은 파도처럼 거세게 밀려오는 응답들에 대한 방파제 역할을 해준다. <br>
우리 주변에서 흔히 볼 수 있는 캐싱의 예로는 DNS 캐싱, CPU 캐시, CDN 등이 있다.

<br>

### HTTP 통신 관점에서 캐시 접근
위에서 이야기한 것처럼 캐시는 시스템에 가해지는 부하를 줄이고 응답을 빠르게 처리하기 위해 사용된다. <br>
'응답을 빠르게 처리하다.'는 매우 중요한 문제이기 때문에 이를 위해 많은 서비스 회사들이 막대한 자금을 투자한다. <br>
그렇다면 캐시는 어떤 방식을 통해 요청에 대한 응답을 빠르게 보낼까? 이에대해서 간단한 플로우를 살펴본다.

HTTP 통신 플로우
1. 리소스 요청
2. 리소스에 대한 응답

리소스 요청에 대한 응답을 내려줄 때 그 속도는 리소스 유형에 따라 달라진다. <br>
리소스 유형에 따라 '정적 리소스 파일에 대한 I/O', 'DB 접근', '다른 API 서버와의 통신' 등등 <br>
요청 처리를 위한 프로세스가 다양하다.

캐시는 요청에 대한 응답을 사전에 저장해두고* 같은 요청이 오면 처리하지 않고 이를 내려주는 과정에서 <br>
미리 저장되는 데이터를 의미한다. 

\* 저장위치는 '애플리케이션 서버', '스토리지 서버' 등 상황에 따라 달라진다.

<br>

### 캐시 데이터는 어떤 기준으로 설정해야하는가?
캐시데이터 설정에 고려할만한 사항들은 다음과 같다.

- 조회 비용
- 조회의 빈번성 (캐시 히트율과 연결)
- 데이터 정합성


### 서비스 적용
현재 유의미한 데이터가 존재하지 않기 때문에 조회비용 측면에서 캐시를 고려하면 부합하지 않는다. <br>
이와 달리 비즈니스 로직 측면에서 보면 콘서트 일정목록을 조회하는 것은 계속 기능을 이용하는데 있어서 <br>
꼭 필요함과 동시에 데이터 정합성이 잘 깨지지 않는 API 기능이다.

이 측면에서 현재 프로젝트에서는 콘서트 일정목록 조회 API에 캐시기능을 적용하여 <br>
예상치 못한 트래픽에 문제가 생기지 않도록 성능을 개선한다.


