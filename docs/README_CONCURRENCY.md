# 동시성 이슈 분석 및 해결방안 탐구

## 서론
 본 프로젝트에서 제공하는 서비스의 메인 도메인은 '콘서트 예약' 기능이다. 콘서트 좌석을 예약하기 위해 필요한 <br>
기능('콘서트별 공연날짜 확인', '특정 공연날짜에 예약가능한 좌석 정보', '공연 좌석 예약', '예약 건 결제', <br>
'결제를 위한 포인트 충전', '포인트 조회')는 공연별로 구성되는 대기열을 통과한 사용자들만이 이용할 수 있다.

여기서 우리는 1)'좌석 예약', 2)'포인트 충전 및 예약 건 결제' 기능에 주의를 기울일 필요가 있다. <br>
1), 2)가 다른 기능들과 구별되는 점은 다수의 요청(여러 사용자 혹은 단일 사용자의 연속적인 기능 호출)이 <br>
동일한 기능 대상의 상태(value)를 변경하는 경우가 생기기 때문이다. <br>
이러한 상황에서 여러 요청에 따른 작업이 수행된 후 처리 결과를 확인했을 때 예상과 다른 결과 값이 조회되어 데이터의 신뢰성을 떨어트리게 된다.

이처럼 다수의 작업 프로세스가 공통된 리소스에 접근하여 상태를 변경하고자 할 때 발생하는 문제를 **동시성 이슈**라고 한다.

<br>
<br>

## 동시성 이슈 분석   

### i. 좌석 예약
'좌석예약' 기능에서 예상되는 동시성 이슈 문제는 `중복 예약`이다. <br>
두 명 이상의 사용자가 동일한 좌석을 예약할 때, 첫번째로 신청된 예약 작업이 종료되기 전
다른 예약 작업이 수행되는 상황에서 발생한다. <br>
이에 대한 간단한 예시로 아래 [그림 1]을 살펴본다.

<br>

[그림 1 : 중복예약 문제] <br>
![image](https://github.com/user-attachments/assets/a0b55b17-547b-451d-b534-59437cde86d0)

[그림 1]은 `좌석 A`에 대한 일련의 두 요청이 발생한 상황을 가정한다. <br>
예약기능의 프로세스는 요청한 좌석을 조회한 후 점유상태를 확인하고, 점유 상태가 아니라면 해당 좌석을 예약처리하는 것이다. <br>
따라서, 좌석 예약에 성공한다면 해당 좌석의 상태는 점유 상태로 바뀌고 다른 사용자들은 예약할 수 없어야한다. <br>
[그림 1]을 살펴보면 두번째 요청은 첫번째 요청이 처리되기 전 좌석정보를 읽어오기 때문에 좌석의 상태는 점유상태가 아니고
예약을 성공하게 된다. <br> 

결론적으로 좌석예약 기능에서 동시성 이슈가 발생하면 실패해서 존재하지 않아야할 두 번째 좌석 예약성공 데이터가 생성될 수 있다. <br>
이처럼 한 작업 단위(트랜잭션)의 진행 도중 다른 작업이 새로운 데이터를 삽입하거나 수정하여, <br>
이전에 없던 데이터가 나타나거나 존재하지 않아아햘 중복 데이터가 발생하는 현상을 **팬텀 리드**(Phantom Read) 현상이라 한다.

<br>

### ii. 포인트 잔액
'포인트 잔액' 기능에서 예상되는 동시성 이슈 문제는 `데이터 불일치`다. <br>
사용자의 결제처리(혹은 포인트 충전) 요청이 처리되기 전에 포인트 충전(혹은 결제처리) 요청이 처리되는 상황에서 발생한다. <br>
이에 대한 간단한 예시로 아래 [그림 2]를 살펴본다.

<br>

[그림 2 : 데이터 불일치 문제] <br>
![image](https://github.com/user-attachments/assets/efcfcf2a-d038-48aa-b741-4f79bbd920ad)

[그림 2]는 임의의 사용자 A의 포인트에 대한 결제와 충전 상황을 가정한다. 결제 기능을 단순화하여 포인트 도메인 측면만 바라본다면, <br>
결제 기능 프로세스는 '사용자의 포인트를 조회하고 결제 금액에 해당하는 포인트를 차감한 뒤 그 잔액으로 사용자의 포인트를 수정'하는 흐름이다. <br>
이와 반대로 충전 기능은 '사용자 포인트를 조회하고 충전 금액에 해당하는 포인트를 추가한 뒤 그 합계액으로 사용자 포인트를 수정'하는 프로세스를 갖는다.

정상적인 경우라면 결제가 처리된 이후의 사용자 포인트에 대해서 충전이 처리되어야 하지만 <br>
[그림 2]의 충전 요청은 결제가 처리되기 전 사용자 포인트를 기준 포인트로 삼는다. <br>
충전 작업을 위한 기준 포인트는 8500p가 아닌 10000p가 되고 프로세스 처리 후 포인트는 10500p가 아닌 12000p로 조회된다. <br>

결론적으로 결제와 포인트 충전 기능에서 동시성 이슈가 발생하면 처리된 데이터가 정상적으로 반영되지 않을 수 있다. <br>
이 처럼 두 트랜잭션이 동시에 같은 데이터를 읽고 수정할 때, 나중에 완료된 트랜잭션이 먼저 완료된 <br>
트랜잭션의 결과를 덮어쓰면서 데이터 변경이 유실되는 현상을 **유실된 갱신**(Lost Update) 현상이라 한다.

<br>
<br>

## 동시성 제어 기법

### i. 데이터베이스 락 (DB Locking)

애플리케이션에서 DB의 데이터(레코드) 변경을 제한하거나 잠금으로써 동시성 문제를 해결할 수 있다. <br>
이를 위한 대표적인 방식으로 낙관적 락과 비관적 락이 있다.

낙관적 락(Optimistic Lock)은 트랜잭션의 동시 업데이트가 빈번하지 않을 것이라고 가정하고 <br>
버전 관리를 통해 충돌을 감지하는 방식이다. 실제 DB 락을 사용하지 않아 성능상 이점이 있지만, 충돌 시 롤백이 필요하다. <br>
일반적으로 나중에 요청된 업데이트를 실패(롤백)처리한다.

비관적 락(Pessimistic Lock)은 동시성 충돌이 빈번할 것으로 예상되는 경우 사용되며, <br>
DB 락을 통해 트랜잭션의 충돌을 방지한다. DB 락은 여러 트랜잭션이 동시에 동일한 데이터를 변경하지 못하도록 <br> 
막아 데이터의 무결성을 보호하는 시스템이지만 성능 비용을 초래할 수 있다.
공유 락(S-Lock)과 베타 락(X-Lock)이 DB락의 주요 유형이다.

<br>

```text
[참고]

- 공유락
  - 공유락은 레코드를 읽기 위해 사용하는 잠금이다. (읽기 잠금)
  - 공유락처리된 레코드를 다른 트랜잭션 역시 읽을 수 있으나 수정(update)은 불가능하다. (읽기의 무결성 - Repeatable Read) 
  - 공유잠금이 해제될 때까지 업데이트 잠금
  
- 베타락
  - 베타락은 레코드를 쓰기 위해 사용하는 잠금이다. (쓰기 잠금)
  - 베타락을 가진 트랜잭션은 레코드 읽기/쓰기가 가능하지만, 다른 트랜잭션의 접근(공유락/베타락 획득)을 제한한다. (Serealizable)
  - 트랜잭션이 종료(커밋 or 롤백)될 때까지 잠금이 유지된다.
```


<br>

### ii. 분산락 (Distributed Lock)

분산락은 여러 서버나 프로세스가 공유 자원에 접근할 때, 동시성을 제어하기 위해 사용하는 동기화 메커니즘이다. <br>
예를 들어, 여러 서버에서 동시에 같은 데이터의 정보를 업데이트 할 때 분산락을 통해 한 번에 하나의 서버만 데이터를 수정할 수 있도록 보장한다. <br>
분산락은 Redis나 ZooKeeper와 같은 공통 저장소를 활용하여 자원의 사용 여부를 체크하는 방식으로 구현된다. <br>
(Redis와 ZooKeeper는 데이터 저장 방식에 차이가 있다. 이후 '분산락'에 대한 설명은 Redis를 기준으로 진행한다.)

Redis는 인메모리 기반의 고성능 키-값 저장소로, 분산락을 구현하는 데 널리 사용되는 솔루션이다. <br>
Redis에서 락을 획득한다는 의미는 '락의 존재여부 확인'과 '존재하지 않을 경우 락 획득'라는 두가지 행위가 <br>
원자적(Atomic)으로 이루어진다는 것을 나타낸다. 락을 획득할 때 사용하는 SETNX(SET if Not eXists) 명령어가 이를 잘 나타낸다.

```text
[Redis 사용방식]
아래 3가지 방식 모두 키(key) 선점에 의한 락 획득 방식을 사용한다. (SETNX)

- Simple Lock : 락 획득 실패 시 비즈니스 로직을 수행하지 않는다.
- Spin Lock : 락 획득 실패 시 일정 시간 혹은 횟수 동안 락 획득을 재시도한다.
- Pub / Sub
  - 메시지 발행자(Publisher)와 구독자(Subscriber) 간의 실시간 메시지 전달을 지원하는 메시징 패턴을 사용한다.
  - redis(발행자)로부터 lock 데이터를 요청하고 비즈니스 로직을 처리한 후 이를 반환한다. (각 서버는 구독자가 된다.)
```


<br>

### iii. 카프카 (Kafka Messaging)

Kafka는 분산 메시징 시스템으로, 메시지의 순서를 보장하는 파티션(메시지 큐)과 이를 처리하는 컨슈머를 통해 <br> 
효과적으로 동시성 문제를 해결한다. 구체적으로, Kafka 프로듀서가 메시지를 발행하면 브로커는 이를 파티션에 저장하고, <br>
컨슈머는 파티션에서 순서가 보장된 메시지들을 차례로 가져가 처리한다.

<img src="https://github.com/user-attachments/assets/cc606a98-e2a9-4fbe-8920-4d6e82ece20d" width="700px" height="250px">

<br>

## 기술 분석 및 검토

### i. 기술별 특징 및 적합성 평가

지금까지 동시성 이슈를 방지하기 위해 다룬 각 기술 별 특징을 정리하면 다음과 같다.

<br>

1. DB 락 메커니즘

- 낙관적 락
   - 특징: 충돌이 적을 것이라 낙관적으로 가정하고 버전 관리를 통해 동시성 제어 
   - 장점
     - 동시 요청이 적을 때 성능이 좋다. 
     - 실제 DB 락이 없어 교착상태가 발생하지 않는다. 
     - 구현이 상대적으로 단순하다. 
   - 단점 
     - 충돌 시 재시도 로직이 필요
     - 높은 동시성 환경에서 성능 저하 (사용하면 안된다.)
   - 적합한 상황
     - 읽기가 많고 쓰기가 적은 경우 
     - 충돌 가능성이 낮은 경우 
     - 트래픽이 적은 경우


- 비관적 락
  - 특징 : 충돌이 발생할 것이라 비관적으로 가정하고 DB 수준의 락을 통해 동시성 제어
  - 장점
    - 데이터 정합성 보장이 확실 
    - 충돌이 많은 경우 성능이 좋음 
    - 별도의 재시도 로직 불필요 
  - 단점 
    - 동시성 감소 
    - 데드락(Dead Lock) 가능성 존재 (교착상태)
    - 성능 오버헤드 발생 
  - 적합한 상황 
    - 쓰기가 많은 경우 
    - 데이터 정합성이 매우 중요한 경우 
    - 충돌이 자주 발생하는 경우

<br>

2. 분산락
- 특징 : 여러 서버에서 공유 리소스 접근을 제어하기 위한 분산 환경의 락 메커니즘
- 장점
  - 분산 환경에서 동시성 제어 가능 
  - 확장성이 좋음 
  - 유연한 락 관리 가능 
- 단점
  - 추가적인 인프라(Redis 등) 필요 
  - 네트워크 지연 발생 가능 
  - 구현 복잡도가 높음
- 적합한 상황 
  - 마이크로서비스 아키텍처 
  - 분산 환경에서의 동시성 제어 
  - 서버 간 리소스 공유가 필요한 경우 

<br>

3. Kafka
- 특징: 메시지 큐를 통한 비동기 처리로 동시성 제어 
- 장점 
  - 높은 처리량과 확장성 
  - 메시지(요청) 순서 보장 
  - 장애 복구 용이 
- 단점 
  - 실시간 처리가 어려움 
  - 추가적인 인프라 필요 
  - 운영 복잡도 증가 
- 적합한 상황 
  - 대용량 데이터 처리 
  - 비동기 처리가 가능한 경우 
  - 순차적 메시지 처리가 필요한 경우

<br>

각 동시성 제어 메커니즘은 고유한 특징과 장단점을 가지고 있으며, 시스템의 요구사항과 특성에 따라 <br>
적절한 선택이 필요하다. 본 서비스에서 '예약'기능은 콘서트 예매 시점에 다수의 사용자가 접속하여 일부 동일한 <br>
좌석에 동시 예약요청을 할 가능성이 존재하여 높은 동시성을 갖추어야 한다. <br>
이와 더불어 사용자 포인트는 실제 돈과 연결되기 때문에 높은 데이터 정합성이 보장되어야 한다. <br>
이러한 두가지 요인을 기반으로 낙관적 락은 도입 검토 기술대상에서 제외하도록 한다.  

다수의 요청은 높은 동시성을 통해 한개씩 처리되어진다. 좌석 예약 프로세스를 다시 살펴보면, 1) 베타적인 <br> 
방식으로 좌석을 조회하고 2) 좌석이 비었으면 좌석을 예약한다. 즉, 해당 프로세스가 진행되면 좌석은 점유된다. <br> 
따라서 여러 사용자가 동시에 좌석 예약을 신청했을 때 우선권을 얻지 못한 사용자들은 예약을 실패해야한다.

이를 반영하여 우선권(락)을 얻기 위해 계속 서버에 이를 요청하거나 대기하는 Spin lock과 pub/sub 방식은 <br>
제외하도록 한다. 물론 우선권을 얻은 사용자가 좌석을 예약하지 못하는 경우가 있겠지만 이는 소수에 불과할 <br>
것으로 판단되며 프론트 영역에서 충분히 우선권 획득을 위한 재요청을 진행 할 수 있다. 이러한 예외케이스를 <br>
보장하기 위해 서버 리소스를 투자하는 것은 전체 서버에 대한 부하 및 장애를 가져올 수 있기 때문이다. <br>

** Kafka는 구조가 복잡하고 도입 시 높은 기술적 이해가 필요하기 때문에, 이번 도입 대상에서 제외하도록 한다.


<br>

### ii. 성능 테스트

<br>

#### 좌석예약

팬텀리드 현상을 방지하기 위해 높은 동시성이 필요한 '좌석예약'기능은 분산락 또는 비관적락을 사용할 수 있다. <br>
두 기술 중 더 적절한 기술을 찾기 위해 테스트를 진행한다. 분산락 방식은 기본락을 사용하며 락 제어권 얻기를 <br>
실패하면 예약은 실패한다. (레디스에서 제어권을 얻은 후 이어지는 트랜잭션에서는 DB락을 사용하지않는다.) <br>
비관적락은 베타락을 사용해서 좌석에 대한 다른 트랜잭션의 조회 및 수정을 제한한다.  

테스트는 동일한 좌석에 대해서 무작위의 사용자가 동시에 예약 신청을 하는것으로 가정하였으며, <br>
동시 신청 테스트 케이스는 10건, 5000건, 10000건으로 구성되어있다. 각각의 테스트는 테스트 진행 전 <br>
Warm Up을 위해 3번의 테스트를 진행한 뒤 실행 후 측정하였으며, 실제 처리 시간은 각 이미지 우측 <br>
콘솔 화면에 있는 `times`이다. (ms 단위)

<br>

- 10건
  - 분산락 <br>
    ![image](https://github.com/user-attachments/assets/52cb87db-a0cd-44e9-94d9-9f9b70d9cfd4)
  - 비관적 락 <br>
    ![image](https://github.com/user-attachments/assets/2e3e05ef-b05f-4868-bb8b-b6493c2234e1)


- 5000건
  - 분산락 <br>
    ![image](https://github.com/user-attachments/assets/5eebcf5c-00bf-474b-85ed-99c26485845f)
  - 비관적 락 <br>
    ![image](https://github.com/user-attachments/assets/3a204090-1b7c-4cfd-a40d-e5329fe80602)


- 10000건
  - 분산락 <br>
    ![image](https://github.com/user-attachments/assets/998ab5e3-cf94-45cf-859d-d5ccd6bd0358)
  - 비관적 락 <br>
    ![image](https://github.com/user-attachments/assets/e763fe54-c71e-41a4-9b16-0bd3f2a91de5)


5000명, 10000명처럼 많은 사용자가 동시에 신청할 경우 분산락은 빠른 처리속도를 보여준다. 이와 달리 10명 이하의 <br> 
소수의 예약요청이 동시에 들어오면 비관적락이 더 높은 처리능력을 보인다. 

<br>

### iv. 검토 결과

콘서트의 인기에 따라 짧은 시간 내에 많은 요청을 처리해야하는 처리할 수도 있는 예약기능에는 분산락을 도입하여 <br> 
작업 우선권을 얻은 사용자는 예약에 성공하고 그외 사용자는 실패처리하도록 한다. 이와 더불어 별도의 테스트는 <br>
진행하지 않았지만 위 '좌석예약' 테스트의 결과를 참고하여 사용자 포인트를 관리하는 기능에는 비관적락을 사용한다. <br>
사용자 포인트는 높은 데이터 정합성을 필요로하면서 동시성 이슈 발생가능성은 상대적으로 낮기 때문이다.


<br>

## References

---
- Difference between shared lock and exclusive lock <br>
  https://www.geeksforgeeks.org/difference-between-shared-lock-and-exclusive-lock/
- Redis official web site docs <br>
  https://redis.io/docs/latest/develop/use/patterns/distributed-locks/
- 하이퍼커넥트 : 레디스를 활용한 분산 락과 안전하고 빠른 락의 구현 <br>
  https://hyperconnect.github.io/2019/11/15/redis-distributed-lock-1.html
- Distributed locking mechanism using redis <br>
  https://medium.com/@anil.goyal0057/distributed-locking-mechanism-using-redis-26c17d9f3d5f
- What is Apache Kafka? <br>
  https://learn.conduktor.io/kafka/what-is-apache-kafka/
